# ğŸ§ª Kafka Beginner Project

Welcome to the Kafka Beginner Project! This repository provides a simple, beginner-friendly example of how Apache Kafka can be used for messaging between microservices.

---

## ğŸ“¸ Architecture Overview

![Kafka Microservices Implementation](Implementation.png)

---

## ğŸ§© Project Structure

This project consists of **three services** that communicate using Kafka as the messaging backbone.

### ğŸ”¹ Service 1 (`Order service`)
- **Role**: Producer
- **Description**: Generates messages (events) and pushes them to a Kafka topic.

### ğŸ”¹ Service 2 (`Stocks service`)
- **Role**: Consumer
- **Description**: Listens to messages from Kafka and processes them.

### ğŸ”¹ Service 3 (`Email service`)
- **Role**: Consumer / Logger
- **Description**: Another consumer that logs or stores the messages for auditing or secondary processing.

---

## ğŸ”„ Kafka Messaging Flow

1. `Order service` publishes messages to a Kafka topic.
2. `Stocks` and `Email` both subscribe to that topic.
3. Kafka ensures that each consumer gets a copy of the message (fan-out model).

---

## ğŸš€ Getting Started

### Prerequisites
- Docker & Docker Compose (or install Kafka & Zookeeper manually)
- Spring boot  / Java installed and set up

### ğŸ› ï¸ To Run Using Docker
```bash
docker-compose up --build
```
# Kafka Best Practices Checklist  

---

## âš™ï¸ Setup & Infrastructure
- Latest stable Kafka version
- â‰¥ 3 brokers (odd number)
- Use partitions for scalability
- Replication factor â‰¥ 3
- KRaft mode if new cluster
- Fast SSDs; separate OS/log disks
- Monitor broker & disk health

## ğŸ›¡ Security
- Enable TLS/SSL encryption
- Use SASL/SCRAM for authentication
- Configure ACLs for topic access
- Secure schema registry & Connect

## ğŸ“¦ Topic Design
- Clear naming (`orders.created`)
- Choose partition count wisely
- Set cleanup policy (delete vs compact)
- Avoid too many small topics

## ğŸ“ Producer Best Practices
- Enable idempotence
- Use compression (lz4/zstd)
- Batch records (linger.ms, batch.size)
- Handle retries/timeouts
- Use keys to control partitioning

## ğŸ“¥ Consumer Best Practices
- Use consumer groups
- Understand offset commit strategies
- Tune poll configs
- Handle rebalances
- Avoid slow consumers (prevent lag)

## ğŸ“¡ Inter-service Design
- Prefer async/event-driven
- Version schemas & use registry
- Support backward/forward compatibility

## ğŸ“Š Monitoring & Observability
- Prometheus + Grafana
- Kafka UI tools (AKHQ, Conduktor)
- Distributed tracing (Jaeger, Zipkin)
- Monitor consumer lag & broker metrics

## ğŸ”„ Operations
- Automate topic creation (IaC)
- CI/CD for configs & deployments
- Plan scaling (partitions, brokers)
- Backup & test disaster recovery
- Rolling restarts for upgrades

## âš¡ Application Coding
- Avoid blocking calls in reactive apps
- Use retries & dead letter topics
- Keep consumers idempotent
- Add context (correlation IDs)

## ğŸ§ª Testing & Quality
- Use testcontainers for integration
- Mock Kafka only in unit tests
- Contract testing for schema changes

---
**Summary:**
- Secure by default
- Partition wisely
- Monitor everything
- Automate deployment
- Idempotent consumers
- Schema registry for evolution

  # ğŸ³ Kafka with KRaft â€” Quick Reference

Direct, essential CLI & setup notes for running Apache Kafka in KRaft mode (no ZooKeeper).

---

## âš™ï¸ Setup Kafka in KRaft Mode

```bash
# Generate a unique cluster ID
bin/kafka-storage.sh random-uuid

# Format storage using the generated cluster ID
bin/kafka-storage.sh format -t <cluster-id> -c config/kraft/server.properties

# Start the Kafka broker
bin/kafka-server-start.sh config/kraft/server.properties
```
# ğŸŒ Avoid Using localhost
Edit config/kraft/server.properties:
```bash
listeners=PLAINTEXT://0.0.0.0:9092
advertised.listeners=PLAINTEXT://192.168.1.50:9092
```
## ğŸ“Œ Topic Management
```bash
# Create topic
kafka-topics.sh --bootstrap-server <host:port> --create --topic my_topic

# Create topic with partitions and replication factor(1 since locally we have 1 broker)
kafka-topics.sh --bootstrap-server localhost:9092 --create --topic second_topic --partitions 3 --replication-factor 1

# List topics
kafka-topics.sh --bootstrap-server <host:port> --list

# Describe topic
kafka-topics.sh --bootstrap-server <host:port> --describe --topic my_topic

# Delete topic
kafka-topics.sh --bootstrap-server <host:port> --delete --topic my_topic
```
## âœï¸ Produce & Consume Messages
```bash
# Produce messages
kafka-console-producer.sh --bootstrap-server <host:port> --topic my_topic

# Consume from beginning
kafka-console-consumer.sh --bootstrap-server <host:port> --topic my_topic --from-beginning

# Consume new messages
kafka-console-consumer.sh --bootstrap-server <host:port> --topic my_topic

```

## ğŸ› ï¸ Manage Partitions & Configs
```bash
# Increase partitions
kafka-topics.sh --bootstrap-server <host:port> --alter --topic my_topic --partitions 3

# Add/update topic config
kafka-configs.sh --bootstrap-server <host:port> --entity-type topics \
  --entity-name my_topic --alter --add-config retention.ms=86400000

# Describe topic config
kafka-configs.sh --bootstrap-server <host:port> --entity-type topics \
  --entity-name my_topic --describe
```
## ğŸ‘¥ Consumer Groups
```bash
# List groups
kafka-consumer-groups.sh --bootstrap-server <host:port> --list

# Describe group
kafka-consumer-groups.sh --bootstrap-server <host:port> --describe --group my_group

# Delete group
kafka-consumer-groups.sh --bootstrap-server <host:port> --delete --group my_group

```




